{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2d59153-0fb9-42c5-aea0-b2574b7c3f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chrX.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr12.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr11.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr1.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr14.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr16.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr13.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr7.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr2.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr21.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr6.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr22.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr9.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr4.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr18.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr3.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr19.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr8.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr20.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr15.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr5.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr10.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Processing topchef_freeze10b/snps_indels50_mac1/freeze.10b.chr17.pass_only.snps_indels50_mac1_phased.TOPchef.vcf.gz...\n",
      "Aggregated SNP counts saved to gene_consequence_snp_counts.txt.gz!\n"
     ]
    }
   ],
   "source": [
    "# Connor Murray\n",
    "# Started 12.14.2024\n",
    "# Extract metadata from SNPEff annotated VCFs\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "\n",
    "# Working directory\n",
    "os.chdir(\"/standard/vol185/cphg_Manichaikul/users/csm6hg\")\n",
    "\n",
    "# Function to parse the annotation (column 8)\n",
    "def extract_annotation(info_column):\n",
    "    \"\"\"Extract the annotation (ANN=) from the INFO column.\"\"\"\n",
    "    for field in info_column.split(\";\"):\n",
    "        if field.startswith(\"ANN=\"):\n",
    "            field_value = field.split(\"=\", 1)[1]\n",
    "            annotation_parts = field_value.split(\"|\")\n",
    "            if len(annotation_parts) > 4:\n",
    "                return {\n",
    "                    \"consequence\": annotation_parts[1],\n",
    "                    \"gene\": annotation_parts[4]\n",
    "                }\n",
    "    return {\"consequence\": None, \"gene\": None}\n",
    "\n",
    "# List to store intermediate results\n",
    "gene_consequence_counts = []\n",
    "\n",
    "# Read VCF files\n",
    "vcf_files = glob.glob(\"topchef_freeze10b/snps_indels50_mac1/*pass_only*.vcf.gz\")\n",
    "\n",
    "# Go through each VCF\n",
    "for vcf_file in vcf_files:\n",
    "    print(f\"Processing {vcf_file}...\")\n",
    "    \n",
    "    # Open and read the VCF file in chunks to save memory\n",
    "    with gzip.open(vcf_file, 'rt') as f:\n",
    "        # Read the VCF file into a pandas DataFrame, skipping header lines\n",
    "        vcf_data = pd.read_csv(\n",
    "            f,\n",
    "            sep=\"\\t\",\n",
    "            comment=\"#\",\n",
    "            header=None,\n",
    "            usecols=range(8), # This makes things so much faster - skip all genotype info\n",
    "            names=[\"chrom\", \"pos\", \"rsid\", \"ref\", \"alt\", \"qual\", \"filter\", \"info\"]\n",
    "        )\n",
    "    \n",
    "    # Extract annotation from the INFO column\n",
    "    annotations = vcf_data[\"info\"].apply(extract_annotation)\n",
    "    annotation_df = pd.DataFrame(annotations.tolist())  # Convert list of dicts to DataFrame\n",
    "    \n",
    "    # Combine extracted annotations with main VCF data\n",
    "    vcf_data = pd.concat([vcf_data, annotation_df], axis=1)\n",
    "    \n",
    "    # Filter out rows with missing annotation\n",
    "    vcf_data = vcf_data.dropna(subset=[\"gene\", \"consequence\"])\n",
    "    \n",
    "    # Group by gene and consequence, and count the number of SNPs\n",
    "    grouped = vcf_data.groupby([\"gene\", \"consequence\"]).size().reset_index(name=\"snp_count\")\n",
    "    gene_consequence_counts.append(grouped)\n",
    "\n",
    "# Combine counts from all files\n",
    "final_counts = pd.concat(gene_consequence_counts, ignore_index=True)\n",
    "\n",
    "# Aggregate again in case of overlaps across files\n",
    "final_counts = final_counts.groupby([\"gene\", \"consequence\"]).sum().reset_index()\n",
    "\n",
    "# Save the final aggregated data\n",
    "output_file = \"gene_consequence_snp_counts.txt.gz\"\n",
    "with gzip.open(output_file, 'wt') as gz_file:\n",
    "    final_counts.to_csv(gz_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Aggregated SNP counts saved to {output_file}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
